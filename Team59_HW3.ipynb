{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# To support both python 2 and python 3\n",
    "from __future__ import division, print_function, unicode_literals\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold  # import sklearn Kfold to implement cross-validation\n",
    "\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "def reset_graph(seed=42):\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "reset_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# load data: digits 5 to 9, but still label with 0 to 4, \n",
    "# because TensorFlow expects label's integers from 0 to n_classes-1.\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"/tmp/data/\")\n",
    "\n",
    "X_train2_full = mnist.train.images[mnist.train.labels >= 5]\n",
    "y_train2_full = mnist.train.labels[mnist.train.labels >= 5] - 5\n",
    "\n",
    "X_valid2_full = mnist.validation.images[mnist.validation.labels >= 5]\n",
    "y_valid2_full = mnist.validation.labels[mnist.validation.labels >= 5] - 5\n",
    "\n",
    "X_test2 = mnist.test.images[mnist.test.labels >= 5]\n",
    "y_test2 = mnist.test.labels[mnist.test.labels >= 5] - 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# we want to keep only 100 instances per class in the training set \n",
    "# and let's keep only 30 instances per class in the validation set\n",
    "# tesing set is already loaded above\n",
    "def sample_n_instances_per_class(X, y, n=100):\n",
    "    Xs, ys = [], []\n",
    "    for label in np.unique(y):\n",
    "        idx = (y == label)\n",
    "        Xc = X[idx][:n]\n",
    "        yc = y[idx][:n]\n",
    "        Xs.append(Xc)\n",
    "        ys.append(yc)\n",
    "    return np.concatenate(Xs), np.concatenate(ys)\n",
    "\n",
    "X_train2, y_train2 = sample_n_instances_per_class(X_train2_full, y_train2_full, n=100)\n",
    "X_valid2, y_valid2 = sample_n_instances_per_class(X_valid2_full, y_valid2_full, n=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyper parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr = 5e-3\n",
    "batch_size = 16\n",
    "epochs = 1000\n",
    "saturate_limit = 20  # for applying early stopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## HW 3.1 - Softmax-only transfer-learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# reset the graph\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# load HW2 pre-trained model\n",
    "pretrained_weights_path = './pretrained_hw2_weights/Team59_HW2.ckpt.meta'\n",
    "saver = tf.train.import_meta_graph(pretrained_weights_path)\n",
    "graph = tf.get_default_graph()\n",
    "\n",
    "inputs_num = 784\n",
    "outputs_num = 5\n",
    "\n",
    "X = graph.get_tensor_by_name('X:0')\n",
    "y = graph.get_tensor_by_name('y:0')\n",
    "loss_function = graph.get_tensor_by_name('loss:0')\n",
    "Y_prob = graph.get_tensor_by_name('Y_probability:0')\n",
    "logits = Y_prob.op.inputs[0]\n",
    "accuracy = graph.get_tensor_by_name('accuracy:0')\n",
    "\n",
    "output_layer_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope='logits')\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=lr, name='op_HW3-1')\n",
    "training_op = optimizer.minimize(loss_function, var_list=output_layer_vars)\n",
    "\n",
    "# create hw3-1 saver\n",
    "five_frozen_saver = tf.train.Saver()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 \t Validation loss: 1.32267 \t Best loss: 1.32267 \t Accuracy: 0.42\n",
      "2 \t Validation loss: 0.872994 \t Best loss: 0.872994 \t Accuracy: 0.7\n",
      "3 \t Validation loss: 0.733053 \t Best loss: 0.733053 \t Accuracy: 0.766667\n",
      "4 \t Validation loss: 0.673144 \t Best loss: 0.673144 \t Accuracy: 0.78\n",
      "5 \t Validation loss: 0.639253 \t Best loss: 0.639253 \t Accuracy: 0.8\n",
      "6 \t Validation loss: 0.615424 \t Best loss: 0.615424 \t Accuracy: 0.8\n",
      "7 \t Validation loss: 0.598731 \t Best loss: 0.598731 \t Accuracy: 0.793333\n",
      "8 \t Validation loss: 0.58612 \t Best loss: 0.58612 \t Accuracy: 0.8\n",
      "9 \t Validation loss: 0.576396 \t Best loss: 0.576396 \t Accuracy: 0.806667\n",
      "10 \t Validation loss: 0.568662 \t Best loss: 0.568662 \t Accuracy: 0.8\n",
      "11 \t Validation loss: 0.562381 \t Best loss: 0.562381 \t Accuracy: 0.793333\n",
      "12 \t Validation loss: 0.557183 \t Best loss: 0.557183 \t Accuracy: 0.806667\n",
      "13 \t Validation loss: 0.552812 \t Best loss: 0.552812 \t Accuracy: 0.813333\n",
      "14 \t Validation loss: 0.549086 \t Best loss: 0.549086 \t Accuracy: 0.82\n",
      "15 \t Validation loss: 0.545876 \t Best loss: 0.545876 \t Accuracy: 0.82\n",
      "16 \t Validation loss: 0.543085 \t Best loss: 0.543085 \t Accuracy: 0.82\n",
      "17 \t Validation loss: 0.540644 \t Best loss: 0.540644 \t Accuracy: 0.813333\n",
      "18 \t Validation loss: 0.5385 \t Best loss: 0.5385 \t Accuracy: 0.813333\n",
      "19 \t Validation loss: 0.536613 \t Best loss: 0.536613 \t Accuracy: 0.813333\n",
      "20 \t Validation loss: 0.534951 \t Best loss: 0.534951 \t Accuracy: 0.813333\n",
      "21 \t Validation loss: 0.53349 \t Best loss: 0.53349 \t Accuracy: 0.813333\n",
      "22 \t Validation loss: 0.532211 \t Best loss: 0.532211 \t Accuracy: 0.806667\n",
      "23 \t Validation loss: 0.531096 \t Best loss: 0.531096 \t Accuracy: 0.813333\n",
      "24 \t Validation loss: 0.530133 \t Best loss: 0.530133 \t Accuracy: 0.813333\n",
      "25 \t Validation loss: 0.52931 \t Best loss: 0.52931 \t Accuracy: 0.813333\n",
      "26 \t Validation loss: 0.528616 \t Best loss: 0.528616 \t Accuracy: 0.813333\n",
      "27 \t Validation loss: 0.528044 \t Best loss: 0.528044 \t Accuracy: 0.806667\n",
      "28 \t Validation loss: 0.527585 \t Best loss: 0.527585 \t Accuracy: 0.8\n",
      "29 \t Validation loss: 0.527233 \t Best loss: 0.527233 \t Accuracy: 0.8\n",
      "30 \t Validation loss: 0.526981 \t Best loss: 0.526981 \t Accuracy: 0.806667\n",
      "31 \t Validation loss: 0.526824 \t Best loss: 0.526824 \t Accuracy: 0.806667\n",
      "32 \t Validation loss: 0.526757 \t Best loss: 0.526757 \t Accuracy: 0.806667\n",
      "33 \t Validation loss: 0.526775 \t Best loss: 0.526757 \t Accuracy: 0.806667\n",
      "34 \t Validation loss: 0.526874 \t Best loss: 0.526757 \t Accuracy: 0.806667\n",
      "35 \t Validation loss: 0.527049 \t Best loss: 0.526757 \t Accuracy: 0.806667\n",
      "36 \t Validation loss: 0.527297 \t Best loss: 0.526757 \t Accuracy: 0.806667\n",
      "37 \t Validation loss: 0.527614 \t Best loss: 0.526757 \t Accuracy: 0.813333\n",
      "38 \t Validation loss: 0.527996 \t Best loss: 0.526757 \t Accuracy: 0.813333\n",
      "39 \t Validation loss: 0.528442 \t Best loss: 0.526757 \t Accuracy: 0.813333\n",
      "40 \t Validation loss: 0.528946 \t Best loss: 0.526757 \t Accuracy: 0.813333\n",
      "41 \t Validation loss: 0.529507 \t Best loss: 0.526757 \t Accuracy: 0.813333\n",
      "42 \t Validation loss: 0.530122 \t Best loss: 0.526757 \t Accuracy: 0.82\n",
      "43 \t Validation loss: 0.530789 \t Best loss: 0.526757 \t Accuracy: 0.82\n",
      "44 \t Validation loss: 0.531504 \t Best loss: 0.526757 \t Accuracy: 0.813333\n",
      "45 \t Validation loss: 0.532266 \t Best loss: 0.526757 \t Accuracy: 0.813333\n",
      "46 \t Validation loss: 0.533072 \t Best loss: 0.526757 \t Accuracy: 0.813333\n",
      "47 \t Validation loss: 0.533921 \t Best loss: 0.526757 \t Accuracy: 0.813333\n",
      "48 \t Validation loss: 0.53481 \t Best loss: 0.526757 \t Accuracy: 0.813333\n",
      "49 \t Validation loss: 0.535738 \t Best loss: 0.526757 \t Accuracy: 0.813333\n",
      "50 \t Validation loss: 0.536703 \t Best loss: 0.526757 \t Accuracy: 0.813333\n",
      "51 \t Validation loss: 0.537703 \t Best loss: 0.526757 \t Accuracy: 0.813333\n",
      "INFO:tensorflow:Restoring parameters from ./pretrained_hw3_1_weights/Team59_HW3_1.ckpt\n",
      "============================================================\n",
      "Test data accurancy 0.818967\n",
      "Time: 3.7487239837646484\n",
      "============================================================ \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "t0 = time.time()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "        \n",
    "    # parameters\n",
    "    saturate_count = 0\n",
    "    best_acc = 0.\n",
    "    best_loss = 1000.\n",
    "    best_epoch = -1\n",
    "    iterations = int(X_train2.shape[0] / batch_size)\n",
    "        \n",
    "    # training for number of epochs times\n",
    "    for e in range(1, epochs + 1):\n",
    "        for i in range(iterations):\n",
    "            if(i==0):\n",
    "                batch_x = X_train2[:batch_size]\n",
    "                batch_y = y_train2[:batch_size]\n",
    "            else:\n",
    "                batch_x = X_train2[i * batch_size : (i + 1) * batch_size]\n",
    "                batch_y = y_train2[i * batch_size : (i + 1) * batch_size]\n",
    "                    \n",
    "            sess.run(training_op, feed_dict={X: batch_x, y: batch_y})\n",
    "        \n",
    "        # validate\n",
    "        loss, acc = sess.run([loss_function, accuracy], feed_dict={X: X_valid2, y: y_valid2})\n",
    "        \n",
    "        if best_loss > loss:\n",
    "            save_path = five_frozen_saver.save(sess, \"./pretrained_hw3_1_weights/Team59_HW3_1.ckpt\")\n",
    "            best_acc = acc\n",
    "            best_loss = loss\n",
    "            best_epoch = e\n",
    "            saturate_count = 0\n",
    "        else:\n",
    "            saturate_count += 1\n",
    "\n",
    "            if saturate_count >= saturate_limit:  # stop if saturate\n",
    "                break\n",
    "                \n",
    "        print(e,'\\t', 'Validation loss:', loss, '\\t', 'Best loss:', best_loss, '\\t','Accuracy:', acc)\n",
    "        \n",
    "    t1 = time.time()\n",
    "    \n",
    "# print the test data accurancy\n",
    "with tf.Session() as sess:\n",
    "    five_frozen_saver.restore(sess, \"./pretrained_hw3_1_weights/Team59_HW3_1.ckpt\")\n",
    "    acc_test = accuracy.eval(feed_dict={X: X_test2, y: y_test2})\n",
    "    print('=' * 60)\n",
    "    print('Test data accurancy', acc_test)\n",
    "    print('Time:', (t1-t0))\n",
    "    print('=' * 60, '\\n')\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HW 3.2 - Caching the 5th layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# reset the graph\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# load HW2 pre-trained model\n",
    "pretrained_weights_path = './pretrained_hw2_weights/Team59_HW2.ckpt.meta'\n",
    "saver = tf.train.import_meta_graph(pretrained_weights_path)\n",
    "graph = tf.get_default_graph()\n",
    "\n",
    "inputs_num = 784\n",
    "outputs_num = 5\n",
    "\n",
    "he_init = tf.contrib.layers.variance_scaling_initializer()\n",
    "\n",
    "X = graph.get_tensor_by_name('X:0')\n",
    "y = graph.get_tensor_by_name('y:0')\n",
    "loss_function = graph.get_tensor_by_name('loss:0')\n",
    "Y_prob = graph.get_tensor_by_name('Y_probability:0')\n",
    "logits = Y_prob.op.inputs[0]\n",
    "accuracy = graph.get_tensor_by_name('accuracy:0')\n",
    "\n",
    "output_layer_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope='logits')\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=lr, name='op_HW3-2')\n",
    "training_op = optimizer.minimize(loss_function, var_list=output_layer_vars)\n",
    "\n",
    "# print(tf.get_default_graph().get_operations())\n",
    "\n",
    "# get 5th layer output\n",
    "dense5_output = graph.get_tensor_by_name('logits/MatMul:0')  # logits layer\n",
    "dense5_output.op.inputs[0] # 5th layer output shape(?, 128)\n",
    "\n",
    "# create hw3-2 saver\n",
    "five_cache_saver = tf.train.Saver()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trainging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 \t Validation loss: 1.32267 \t Best loss: 1.32267 \t Accuracy: 0.42\n",
      "2 \t Validation loss: 0.872994 \t Best loss: 0.872994 \t Accuracy: 0.7\n",
      "3 \t Validation loss: 0.733053 \t Best loss: 0.733053 \t Accuracy: 0.766667\n",
      "4 \t Validation loss: 0.673144 \t Best loss: 0.673144 \t Accuracy: 0.78\n",
      "5 \t Validation loss: 0.639253 \t Best loss: 0.639253 \t Accuracy: 0.8\n",
      "6 \t Validation loss: 0.615424 \t Best loss: 0.615424 \t Accuracy: 0.8\n",
      "7 \t Validation loss: 0.598731 \t Best loss: 0.598731 \t Accuracy: 0.793333\n",
      "8 \t Validation loss: 0.58612 \t Best loss: 0.58612 \t Accuracy: 0.8\n",
      "9 \t Validation loss: 0.576396 \t Best loss: 0.576396 \t Accuracy: 0.806667\n",
      "10 \t Validation loss: 0.568662 \t Best loss: 0.568662 \t Accuracy: 0.8\n",
      "11 \t Validation loss: 0.562381 \t Best loss: 0.562381 \t Accuracy: 0.793333\n",
      "12 \t Validation loss: 0.557183 \t Best loss: 0.557183 \t Accuracy: 0.806667\n",
      "13 \t Validation loss: 0.552812 \t Best loss: 0.552812 \t Accuracy: 0.813333\n",
      "14 \t Validation loss: 0.549086 \t Best loss: 0.549086 \t Accuracy: 0.82\n",
      "15 \t Validation loss: 0.545876 \t Best loss: 0.545876 \t Accuracy: 0.82\n",
      "16 \t Validation loss: 0.543085 \t Best loss: 0.543085 \t Accuracy: 0.82\n",
      "17 \t Validation loss: 0.540644 \t Best loss: 0.540644 \t Accuracy: 0.813333\n",
      "18 \t Validation loss: 0.5385 \t Best loss: 0.5385 \t Accuracy: 0.813333\n",
      "19 \t Validation loss: 0.536613 \t Best loss: 0.536613 \t Accuracy: 0.813333\n",
      "20 \t Validation loss: 0.534951 \t Best loss: 0.534951 \t Accuracy: 0.813333\n",
      "21 \t Validation loss: 0.53349 \t Best loss: 0.53349 \t Accuracy: 0.813333\n",
      "22 \t Validation loss: 0.532211 \t Best loss: 0.532211 \t Accuracy: 0.806667\n",
      "23 \t Validation loss: 0.531096 \t Best loss: 0.531096 \t Accuracy: 0.813333\n",
      "24 \t Validation loss: 0.530133 \t Best loss: 0.530133 \t Accuracy: 0.813333\n",
      "25 \t Validation loss: 0.529309 \t Best loss: 0.529309 \t Accuracy: 0.813333\n",
      "26 \t Validation loss: 0.528616 \t Best loss: 0.528616 \t Accuracy: 0.813333\n",
      "27 \t Validation loss: 0.528044 \t Best loss: 0.528044 \t Accuracy: 0.806667\n",
      "28 \t Validation loss: 0.527585 \t Best loss: 0.527585 \t Accuracy: 0.8\n",
      "29 \t Validation loss: 0.527233 \t Best loss: 0.527233 \t Accuracy: 0.8\n",
      "30 \t Validation loss: 0.526981 \t Best loss: 0.526981 \t Accuracy: 0.806667\n",
      "31 \t Validation loss: 0.526824 \t Best loss: 0.526824 \t Accuracy: 0.806667\n",
      "32 \t Validation loss: 0.526757 \t Best loss: 0.526757 \t Accuracy: 0.806667\n",
      "33 \t Validation loss: 0.526775 \t Best loss: 0.526757 \t Accuracy: 0.806667\n",
      "34 \t Validation loss: 0.526874 \t Best loss: 0.526757 \t Accuracy: 0.806667\n",
      "35 \t Validation loss: 0.527049 \t Best loss: 0.526757 \t Accuracy: 0.806667\n",
      "36 \t Validation loss: 0.527297 \t Best loss: 0.526757 \t Accuracy: 0.806667\n",
      "37 \t Validation loss: 0.527614 \t Best loss: 0.526757 \t Accuracy: 0.813333\n",
      "38 \t Validation loss: 0.527997 \t Best loss: 0.526757 \t Accuracy: 0.813333\n",
      "39 \t Validation loss: 0.528442 \t Best loss: 0.526757 \t Accuracy: 0.813333\n",
      "40 \t Validation loss: 0.528946 \t Best loss: 0.526757 \t Accuracy: 0.813333\n",
      "41 \t Validation loss: 0.529507 \t Best loss: 0.526757 \t Accuracy: 0.813333\n",
      "42 \t Validation loss: 0.530122 \t Best loss: 0.526757 \t Accuracy: 0.82\n",
      "43 \t Validation loss: 0.530789 \t Best loss: 0.526757 \t Accuracy: 0.82\n",
      "44 \t Validation loss: 0.531504 \t Best loss: 0.526757 \t Accuracy: 0.813333\n",
      "45 \t Validation loss: 0.532266 \t Best loss: 0.526757 \t Accuracy: 0.813333\n",
      "46 \t Validation loss: 0.533072 \t Best loss: 0.526757 \t Accuracy: 0.813333\n",
      "47 \t Validation loss: 0.533921 \t Best loss: 0.526757 \t Accuracy: 0.813333\n",
      "48 \t Validation loss: 0.53481 \t Best loss: 0.526757 \t Accuracy: 0.813333\n",
      "49 \t Validation loss: 0.535738 \t Best loss: 0.526757 \t Accuracy: 0.813333\n",
      "50 \t Validation loss: 0.536703 \t Best loss: 0.526757 \t Accuracy: 0.813333\n",
      "51 \t Validation loss: 0.537703 \t Best loss: 0.526757 \t Accuracy: 0.813333\n",
      "INFO:tensorflow:Restoring parameters from ./pretrained_hw3_2_weights/Team59_HW3_2.ckpt\n",
      "============================================================\n",
      "Test data accurancy 0.818967\n",
      "Time: 2.777535915374756\n",
      "============================================================ \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "t0 = time.time()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "        \n",
    "    # parameters\n",
    "    saturate_count = 0\n",
    "    best_acc = 0.\n",
    "    best_loss = 1000.\n",
    "    best_epoch = -1\n",
    "    iterations = int(X_train2.shape[0] / batch_size)\n",
    "    \n",
    "    # feed the X_train2 to get the 5th output\n",
    "    logits_train_input = sess.run(dense5_output.op.inputs[0], feed_dict={X: X_train2})\n",
    "        \n",
    "    # training for number of epochs times\n",
    "    for e in range(1, epochs + 1):\n",
    "        for i in range(iterations):\n",
    "            if(i==0):\n",
    "                batch_x = logits_train_input[:batch_size]\n",
    "                batch_y = y_train2[:batch_size]\n",
    "            else:\n",
    "                batch_x = logits_train_input[i * batch_size : (i + 1) * batch_size]\n",
    "                batch_y = y_train2[i * batch_size : (i + 1) * batch_size]\n",
    "            \n",
    "            sess.run(training_op, feed_dict={dense5_output.op.inputs[0]: batch_x, y: batch_y})\n",
    "        \n",
    "        # validate\n",
    "        logits_valid_input = sess.run(dense5_output.op.inputs[0], feed_dict={X: X_valid2})        \n",
    "        loss, acc = sess.run([loss_function, accuracy], feed_dict={dense5_output.op.inputs[0]: logits_valid_input,\n",
    "                                                                   y: y_valid2})\n",
    "        \n",
    "        if best_loss > loss:\n",
    "            save_path = five_cache_saver.save(sess, \"./pretrained_hw3_2_weights/Team59_HW3_2.ckpt\")\n",
    "            best_acc = acc\n",
    "            best_loss = loss\n",
    "            best_epoch = e\n",
    "            saturate_count = 0\n",
    "        else:\n",
    "            saturate_count += 1\n",
    "\n",
    "            if saturate_count >= saturate_limit:  # stop if saturate\n",
    "                break\n",
    "                \n",
    "        print(e,'\\t', 'Validation loss:', loss, '\\t', 'Best loss:', best_loss, '\\t','Accuracy:', acc)\n",
    "        \n",
    "    t1 = time.time()\n",
    "    \n",
    "# print the test data accurancy\n",
    "with tf.Session() as sess:\n",
    "    five_cache_saver.restore(sess, \"./pretrained_hw3_2_weights/Team59_HW3_2.ckpt\")\n",
    "    acc_test = accuracy.eval(feed_dict={X: X_test2, y: y_test2})\n",
    "    print('=' * 60)\n",
    "    print('Test data accurancy', acc_test)\n",
    "    print('Time:', (t1-t0))\n",
    "    print('=' * 60, '\\n')\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result\n",
    "Using cache 5th layer method is faster than Hw3-1.\n",
    "\n",
    "The accuracy is the same value, because the hidden layers aren't trainable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HW 3.3 - 4-layers-only transfer-learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# reset the graph \n",
    "tf.reset_default_graph()\n",
    "\n",
    "# load HW2 pre-trained model\n",
    "pretrained_weights_path = './pretrained_hw2_weights/Team59_HW2.ckpt.meta'\n",
    "saver = tf.train.import_meta_graph(pretrained_weights_path)\n",
    "graph = tf.get_default_graph()\n",
    "\n",
    "inputs_num = 784\n",
    "outputs_num = 5\n",
    "\n",
    "he_init = tf.contrib.layers.variance_scaling_initializer()\n",
    "\n",
    "X = graph.get_tensor_by_name('X:0')\n",
    "y = graph.get_tensor_by_name('y:0')\n",
    "\n",
    "# get 4th layer output\n",
    "dense4_output = graph.get_tensor_by_name('dense4/Elu:0')  # 4th output\n",
    "\n",
    "logits = tf.layers.dense(dense4_output, outputs_num, kernel_initializer=he_init, name=\"HW3-3_logits\")\n",
    "Y_proba = tf.nn.softmax(logits, name='Y_probability')\n",
    "xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "loss_function = tf.reduce_mean(xentropy, name='loss')\n",
    "correct = tf.nn.in_top_k(logits, y, 1)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, tf.float32), name=\"accuracy\")\n",
    "\n",
    "output_layer_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope=\"HW3-3_logits\")\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=lr, name=\"op_HW3-3\")\n",
    "training_op = optimizer.minimize(loss_function, var_list=output_layer_vars)\n",
    "\n",
    "# create hw3_3 saver\n",
    "four_frozen_saver = tf.train.Saver()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 \t Validation loss: 1.39984 \t Best loss: 1.39984 \t Accuracy: 0.54\n",
      "2 \t Validation loss: 0.918001 \t Best loss: 0.918001 \t Accuracy: 0.646667\n",
      "3 \t Validation loss: 0.764278 \t Best loss: 0.764278 \t Accuracy: 0.76\n",
      "4 \t Validation loss: 0.704341 \t Best loss: 0.704341 \t Accuracy: 0.766667\n",
      "5 \t Validation loss: 0.663606 \t Best loss: 0.663606 \t Accuracy: 0.786667\n",
      "6 \t Validation loss: 0.63692 \t Best loss: 0.63692 \t Accuracy: 0.8\n",
      "7 \t Validation loss: 0.617356 \t Best loss: 0.617356 \t Accuracy: 0.82\n",
      "8 \t Validation loss: 0.602766 \t Best loss: 0.602766 \t Accuracy: 0.826667\n",
      "9 \t Validation loss: 0.591605 \t Best loss: 0.591605 \t Accuracy: 0.82\n",
      "10 \t Validation loss: 0.582927 \t Best loss: 0.582927 \t Accuracy: 0.82\n",
      "11 \t Validation loss: 0.576087 \t Best loss: 0.576087 \t Accuracy: 0.82\n",
      "12 \t Validation loss: 0.570631 \t Best loss: 0.570631 \t Accuracy: 0.82\n",
      "13 \t Validation loss: 0.566233 \t Best loss: 0.566233 \t Accuracy: 0.82\n",
      "14 \t Validation loss: 0.562657 \t Best loss: 0.562657 \t Accuracy: 0.82\n",
      "15 \t Validation loss: 0.559729 \t Best loss: 0.559729 \t Accuracy: 0.82\n",
      "16 \t Validation loss: 0.557319 \t Best loss: 0.557319 \t Accuracy: 0.826667\n",
      "17 \t Validation loss: 0.555332 \t Best loss: 0.555332 \t Accuracy: 0.826667\n",
      "18 \t Validation loss: 0.553696 \t Best loss: 0.553696 \t Accuracy: 0.833333\n",
      "19 \t Validation loss: 0.552354 \t Best loss: 0.552354 \t Accuracy: 0.826667\n",
      "20 \t Validation loss: 0.551263 \t Best loss: 0.551263 \t Accuracy: 0.826667\n",
      "21 \t Validation loss: 0.550388 \t Best loss: 0.550388 \t Accuracy: 0.826667\n",
      "22 \t Validation loss: 0.549703 \t Best loss: 0.549703 \t Accuracy: 0.826667\n",
      "23 \t Validation loss: 0.549184 \t Best loss: 0.549184 \t Accuracy: 0.826667\n",
      "24 \t Validation loss: 0.548812 \t Best loss: 0.548812 \t Accuracy: 0.826667\n",
      "25 \t Validation loss: 0.548571 \t Best loss: 0.548571 \t Accuracy: 0.826667\n",
      "26 \t Validation loss: 0.548449 \t Best loss: 0.548449 \t Accuracy: 0.826667\n",
      "27 \t Validation loss: 0.548434 \t Best loss: 0.548434 \t Accuracy: 0.826667\n",
      "28 \t Validation loss: 0.548514 \t Best loss: 0.548434 \t Accuracy: 0.826667\n",
      "29 \t Validation loss: 0.548683 \t Best loss: 0.548434 \t Accuracy: 0.826667\n",
      "30 \t Validation loss: 0.548931 \t Best loss: 0.548434 \t Accuracy: 0.826667\n",
      "31 \t Validation loss: 0.549253 \t Best loss: 0.548434 \t Accuracy: 0.82\n",
      "32 \t Validation loss: 0.549643 \t Best loss: 0.548434 \t Accuracy: 0.82\n",
      "33 \t Validation loss: 0.550094 \t Best loss: 0.548434 \t Accuracy: 0.82\n",
      "34 \t Validation loss: 0.550602 \t Best loss: 0.548434 \t Accuracy: 0.82\n",
      "35 \t Validation loss: 0.551163 \t Best loss: 0.548434 \t Accuracy: 0.82\n",
      "36 \t Validation loss: 0.551773 \t Best loss: 0.548434 \t Accuracy: 0.82\n",
      "37 \t Validation loss: 0.552429 \t Best loss: 0.548434 \t Accuracy: 0.82\n",
      "38 \t Validation loss: 0.553127 \t Best loss: 0.548434 \t Accuracy: 0.82\n",
      "39 \t Validation loss: 0.553864 \t Best loss: 0.548434 \t Accuracy: 0.82\n",
      "40 \t Validation loss: 0.554638 \t Best loss: 0.548434 \t Accuracy: 0.82\n",
      "41 \t Validation loss: 0.555446 \t Best loss: 0.548434 \t Accuracy: 0.82\n",
      "42 \t Validation loss: 0.556285 \t Best loss: 0.548434 \t Accuracy: 0.826667\n",
      "43 \t Validation loss: 0.557155 \t Best loss: 0.548434 \t Accuracy: 0.833333\n",
      "44 \t Validation loss: 0.558052 \t Best loss: 0.548434 \t Accuracy: 0.833333\n",
      "45 \t Validation loss: 0.558975 \t Best loss: 0.548434 \t Accuracy: 0.826667\n",
      "46 \t Validation loss: 0.559922 \t Best loss: 0.548434 \t Accuracy: 0.833333\n",
      "INFO:tensorflow:Restoring parameters from ./pretrained_hw3_3_weights/Team59_HW3_3.ckpt\n",
      "============================================================\n",
      "Test data accurancy 0.82843\n",
      "Time: 2.5447347164154053\n",
      "============================================================ \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "t0 = time.time()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "        \n",
    "    # parameters\n",
    "    saturate_count = 0\n",
    "    best_acc = 0.\n",
    "    best_loss = 1000.\n",
    "    best_epoch = -1\n",
    "    iterations = int(X_train2.shape[0] / batch_size)\n",
    "        \n",
    "    # training for number of epochs times\n",
    "    for e in range(1, epochs + 1):\n",
    "        for i in range(iterations):\n",
    "            if(i==0):\n",
    "                batch_x = X_train2[:batch_size]\n",
    "                batch_y = y_train2[:batch_size]\n",
    "            else:\n",
    "                batch_x = X_train2[i * batch_size : (i + 1) * batch_size]\n",
    "                batch_y = y_train2[i * batch_size : (i + 1) * batch_size]\n",
    "            \n",
    "            sess.run(training_op, feed_dict={X: batch_x, y: batch_y})\n",
    "        \n",
    "        # validate       \n",
    "        loss, acc = sess.run([loss_function, accuracy], feed_dict={X: X_valid2,\n",
    "                                                          y: y_valid2})\n",
    "        \n",
    "        if best_loss > loss:\n",
    "            save_path = four_frozen_saver.save(sess, \"./pretrained_hw3_3_weights/Team59_HW3_3.ckpt\")\n",
    "            best_acc = acc\n",
    "            best_loss = loss\n",
    "            best_epoch = e\n",
    "            saturate_count = 0\n",
    "        else:\n",
    "            saturate_count += 1\n",
    "\n",
    "            if saturate_count >= saturate_limit:  # stop if saturate\n",
    "                break\n",
    "                \n",
    "        print(e,'\\t', 'Validation loss:', loss, '\\t', 'Best loss:', best_loss, '\\t','Accuracy:', acc)\n",
    "        \n",
    "    t1 = time.time()\n",
    "    \n",
    "with tf.Session() as sess:\n",
    "    four_frozen_saver.restore(sess, \"./pretrained_hw3_3_weights/Team59_HW3_3.ckpt\")\n",
    "    acc_test = accuracy.eval(feed_dict={X: X_test2, y: y_test2})\n",
    "    print('=' * 60)\n",
    "    print('Test data accurancy', acc_test)\n",
    "    print('Time:', (t1-t0))\n",
    "    print('=' * 60, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result\n",
    "\n",
    "Using the frozen 4 layers method is better than cache 5 layers.\n",
    "\n",
    "The accurancy value is higher than HW3-1 and HW3-2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HW 3.4 - Bonus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# reset the graph\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Using HW3-3 pre-train model\n",
    "pretrained_weights_path = './pretrained_hw3_3_weights/Team59_HW3_3.ckpt.meta'\n",
    "saver = tf.train.import_meta_graph(pretrained_weights_path)\n",
    "graph = tf.get_default_graph()\n",
    "\n",
    "inputs_num = 784\n",
    "outputs_num = 5\n",
    "\n",
    "he_init = tf.contrib.layers.variance_scaling_initializer()\n",
    "\n",
    "X = graph.get_tensor_by_name('X:0')\n",
    "y = graph.get_tensor_by_name('y:0')\n",
    "\n",
    "# get 4th layer output\n",
    "dense4_output = graph.get_tensor_by_name('dense4/Elu:0')  # 4th output\n",
    "\n",
    "loss_function = graph.get_tensor_by_name('loss:0')\n",
    "Y_prob = graph.get_tensor_by_name('Y_probability:0')\n",
    "logits = Y_prob.op.inputs[0]\n",
    "accuracy = graph.get_tensor_by_name('accuracy:0')\n",
    "\n",
    "# set the 1th 2th hidden layer and logits trainable\n",
    "output_layer_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope=\"dense[12]|HW3-3_logits\")\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=lr, name=\"op_HW3-4\")\n",
    "training_op = optimizer.minimize(loss_function, var_list=output_layer_vars)\n",
    "\n",
    "# create hw3_4 saver\n",
    "two_frozen_saver = tf.train.Saver()\n",
    "\n",
    "# print(tf.get_default_graph().get_operations())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 \t Validation loss: 2.89846 \t Best loss: 2.89846 \t Accuracy: 0.2\n",
      "2 \t Validation loss: 4.11718 \t Best loss: 2.89846 \t Accuracy: 0.533333\n",
      "3 \t Validation loss: 3.42302 \t Best loss: 2.89846 \t Accuracy: 0.393333\n",
      "4 \t Validation loss: 2.92182 \t Best loss: 2.89846 \t Accuracy: 0.573333\n",
      "5 \t Validation loss: 0.829717 \t Best loss: 0.829717 \t Accuracy: 0.746667\n",
      "6 \t Validation loss: 3.11796 \t Best loss: 0.829717 \t Accuracy: 0.486667\n",
      "7 \t Validation loss: 1.30313 \t Best loss: 0.829717 \t Accuracy: 0.686667\n",
      "8 \t Validation loss: 1.12569 \t Best loss: 0.829717 \t Accuracy: 0.766667\n",
      "9 \t Validation loss: 0.720165 \t Best loss: 0.720165 \t Accuracy: 0.826667\n",
      "10 \t Validation loss: 0.505747 \t Best loss: 0.505747 \t Accuracy: 0.82\n",
      "11 \t Validation loss: 0.431741 \t Best loss: 0.431741 \t Accuracy: 0.88\n",
      "12 \t Validation loss: 0.426699 \t Best loss: 0.426699 \t Accuracy: 0.873333\n",
      "13 \t Validation loss: 0.406874 \t Best loss: 0.406874 \t Accuracy: 0.886667\n",
      "14 \t Validation loss: 0.404326 \t Best loss: 0.404326 \t Accuracy: 0.88\n",
      "15 \t Validation loss: 0.405673 \t Best loss: 0.404326 \t Accuracy: 0.893333\n",
      "16 \t Validation loss: 0.40641 \t Best loss: 0.404326 \t Accuracy: 0.886667\n",
      "17 \t Validation loss: 0.411167 \t Best loss: 0.404326 \t Accuracy: 0.886667\n",
      "18 \t Validation loss: 0.415502 \t Best loss: 0.404326 \t Accuracy: 0.886667\n",
      "19 \t Validation loss: 0.41438 \t Best loss: 0.404326 \t Accuracy: 0.906667\n",
      "20 \t Validation loss: 0.413821 \t Best loss: 0.404326 \t Accuracy: 0.913333\n",
      "21 \t Validation loss: 0.414301 \t Best loss: 0.404326 \t Accuracy: 0.913333\n",
      "22 \t Validation loss: 0.414342 \t Best loss: 0.404326 \t Accuracy: 0.926667\n",
      "23 \t Validation loss: 0.415432 \t Best loss: 0.404326 \t Accuracy: 0.926667\n",
      "24 \t Validation loss: 0.417251 \t Best loss: 0.404326 \t Accuracy: 0.926667\n",
      "25 \t Validation loss: 0.419517 \t Best loss: 0.404326 \t Accuracy: 0.926667\n",
      "26 \t Validation loss: 0.421965 \t Best loss: 0.404326 \t Accuracy: 0.933333\n",
      "27 \t Validation loss: 0.424517 \t Best loss: 0.404326 \t Accuracy: 0.933333\n",
      "28 \t Validation loss: 0.427147 \t Best loss: 0.404326 \t Accuracy: 0.933333\n",
      "29 \t Validation loss: 0.429791 \t Best loss: 0.404326 \t Accuracy: 0.933333\n",
      "30 \t Validation loss: 0.432348 \t Best loss: 0.404326 \t Accuracy: 0.933333\n",
      "31 \t Validation loss: 0.434796 \t Best loss: 0.404326 \t Accuracy: 0.933333\n",
      "32 \t Validation loss: 0.437071 \t Best loss: 0.404326 \t Accuracy: 0.933333\n",
      "33 \t Validation loss: 0.439216 \t Best loss: 0.404326 \t Accuracy: 0.933333\n",
      "INFO:tensorflow:Restoring parameters from ./pretrained_hw3_4_weights/Team59_HW3_4.ckpt\n",
      "============================================================\n",
      "Test data accurancy 0.88418\n",
      "Time: 2.694443941116333\n",
      "============================================================ \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "t0 = time.time()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "        \n",
    "    # parameters\n",
    "    saturate_count = 0\n",
    "    best_acc = 0.\n",
    "    best_loss = 1000.\n",
    "    best_epoch = -1\n",
    "    iterations = int(X_train2.shape[0] / batch_size)\n",
    "        \n",
    "    # training for number of epochs times\n",
    "    for e in range(1, epochs + 1):\n",
    "        for i in range(iterations):\n",
    "            if(i==0):\n",
    "                batch_x = X_train2[:batch_size]\n",
    "                batch_y = y_train2[:batch_size]\n",
    "            else:\n",
    "                batch_x = X_train2[i * batch_size : (i + 1) * batch_size]\n",
    "                batch_y = y_train2[i * batch_size : (i + 1) * batch_size]\n",
    "            \n",
    "            sess.run(training_op, feed_dict={X: batch_x, y: batch_y})\n",
    "        \n",
    "        # validate       \n",
    "        loss, acc = sess.run([loss_function, accuracy], feed_dict={X: X_valid2,\n",
    "                                                          y: y_valid2})\n",
    "        \n",
    "        if best_loss > loss:\n",
    "            save_path = two_frozen_saver.save(sess, \"./pretrained_hw3_4_weights/Team59_HW3_4.ckpt\")\n",
    "            best_acc = acc\n",
    "            best_loss = loss\n",
    "            best_epoch = e\n",
    "            saturate_count = 0\n",
    "        else:\n",
    "            saturate_count += 1\n",
    "\n",
    "            if saturate_count >= saturate_limit:  # stop if saturate\n",
    "                break\n",
    "                \n",
    "        print(e,'\\t', 'Validation loss:', loss, '\\t', 'Best loss:', best_loss, '\\t','Accuracy:', acc)\n",
    "        \n",
    "    t1 = time.time()\n",
    "    \n",
    "with tf.Session() as sess:\n",
    "    two_frozen_saver.restore(sess, \"./pretrained_hw3_4_weights/Team59_HW3_4.ckpt\")\n",
    "    acc_test = accuracy.eval(feed_dict={X: X_test2, y: y_test2})\n",
    "    print('=' * 60)\n",
    "    print('Test data accurancy', acc_test)\n",
    "    print('Time:', (t1-t0))\n",
    "    print('=' * 60, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
