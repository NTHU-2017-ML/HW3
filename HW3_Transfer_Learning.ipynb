{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# To support both python 2 and python 3\n",
    "from __future__ import division, print_function, unicode_literals\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold  # import sklearn Kfold to implement cross-validation\n",
    "\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "def reset_graph(seed=42):\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "reset_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# load data: digits 5 to 9, but still label with 0 to 4, \n",
    "# because TensorFlow expects label's integers from 0 to n_classes-1.\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"/tmp/data/\")\n",
    "\n",
    "X_train2_full = mnist.train.images[mnist.train.labels >= 5]\n",
    "y_train2_full = mnist.train.labels[mnist.train.labels >= 5] - 5\n",
    "\n",
    "X_valid2_full = mnist.validation.images[mnist.validation.labels >= 5]\n",
    "y_valid2_full = mnist.validation.labels[mnist.validation.labels >= 5] - 5\n",
    "\n",
    "X_test2 = mnist.test.images[mnist.test.labels >= 5]\n",
    "y_test2 = mnist.test.labels[mnist.test.labels >= 5] - 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# we want to keep only 100 instances per class in the training set \n",
    "# and let's keep only 30 instances per class in the validation set\n",
    "# tesing set is already loaded above\n",
    "def sample_n_instances_per_class(X, y, n=100):\n",
    "    Xs, ys = [], []\n",
    "    for label in np.unique(y):\n",
    "        idx = (y == label)\n",
    "        Xc = X[idx][:n]\n",
    "        yc = y[idx][:n]\n",
    "        Xs.append(Xc)\n",
    "        ys.append(yc)\n",
    "    return np.concatenate(Xs), np.concatenate(ys)\n",
    "\n",
    "X_train2, y_train2 = sample_n_instances_per_class(X_train2_full, y_train2_full, n=100)\n",
    "X_valid2, y_valid2 = sample_n_instances_per_class(X_valid2_full, y_valid2_full, n=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyper parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr = 5e-3\n",
    "batch_size = 16\n",
    "epochs = 1000\n",
    "saturate_limit = 20  # for applying early stopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## HW 3.1 - Softmax-only transfer-learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_weights_path = './pretrained_hw2_weights/Team59_HW2.ckpt.meta'\n",
    "\n",
    "inputs_num = 784\n",
    "outputs_num = 5\n",
    "\n",
    "tf.reset_default_graph()\n",
    "saver = tf.train.import_meta_graph(pretrained_weights_path)\n",
    "graph = tf.get_default_graph()\n",
    "\n",
    "X = graph.get_tensor_by_name('X:0')\n",
    "y = graph.get_tensor_by_name('y:0')\n",
    "loss_function = graph.get_tensor_by_name('loss:0')\n",
    "Y_prob = graph.get_tensor_by_name('Y_probability:0')\n",
    "logits = Y_prob.op.inputs[0]\n",
    "accuracy = graph.get_tensor_by_name('accuracy:0')\n",
    "\n",
    "output_layer_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope='logits')\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=lr, name='op_HW3-1')\n",
    "training_op = optimizer.minimize(loss_function, var_list=output_layer_vars)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 \t Validation loss: 1.32267 \t Best loss: 1.32267 \t Accuracy: 0.42\n",
      "2 \t Validation loss: 0.872994 \t Best loss: 0.872994 \t Accuracy: 0.7\n",
      "3 \t Validation loss: 0.733053 \t Best loss: 0.733053 \t Accuracy: 0.766667\n",
      "4 \t Validation loss: 0.673144 \t Best loss: 0.673144 \t Accuracy: 0.78\n",
      "5 \t Validation loss: 0.639253 \t Best loss: 0.639253 \t Accuracy: 0.8\n",
      "6 \t Validation loss: 0.615424 \t Best loss: 0.615424 \t Accuracy: 0.8\n",
      "7 \t Validation loss: 0.598731 \t Best loss: 0.598731 \t Accuracy: 0.793333\n",
      "8 \t Validation loss: 0.58612 \t Best loss: 0.58612 \t Accuracy: 0.8\n",
      "9 \t Validation loss: 0.576396 \t Best loss: 0.576396 \t Accuracy: 0.806667\n",
      "10 \t Validation loss: 0.568662 \t Best loss: 0.568662 \t Accuracy: 0.8\n",
      "11 \t Validation loss: 0.562381 \t Best loss: 0.562381 \t Accuracy: 0.793333\n",
      "12 \t Validation loss: 0.557183 \t Best loss: 0.557183 \t Accuracy: 0.806667\n",
      "13 \t Validation loss: 0.552812 \t Best loss: 0.552812 \t Accuracy: 0.813333\n",
      "14 \t Validation loss: 0.549086 \t Best loss: 0.549086 \t Accuracy: 0.82\n",
      "15 \t Validation loss: 0.545876 \t Best loss: 0.545876 \t Accuracy: 0.82\n",
      "16 \t Validation loss: 0.543085 \t Best loss: 0.543085 \t Accuracy: 0.82\n",
      "17 \t Validation loss: 0.540644 \t Best loss: 0.540644 \t Accuracy: 0.813333\n",
      "18 \t Validation loss: 0.5385 \t Best loss: 0.5385 \t Accuracy: 0.813333\n",
      "19 \t Validation loss: 0.536613 \t Best loss: 0.536613 \t Accuracy: 0.813333\n",
      "20 \t Validation loss: 0.534951 \t Best loss: 0.534951 \t Accuracy: 0.813333\n",
      "21 \t Validation loss: 0.53349 \t Best loss: 0.53349 \t Accuracy: 0.813333\n",
      "22 \t Validation loss: 0.532211 \t Best loss: 0.532211 \t Accuracy: 0.806667\n",
      "23 \t Validation loss: 0.531096 \t Best loss: 0.531096 \t Accuracy: 0.813333\n",
      "24 \t Validation loss: 0.530133 \t Best loss: 0.530133 \t Accuracy: 0.813333\n",
      "25 \t Validation loss: 0.52931 \t Best loss: 0.52931 \t Accuracy: 0.813333\n",
      "26 \t Validation loss: 0.528616 \t Best loss: 0.528616 \t Accuracy: 0.813333\n",
      "27 \t Validation loss: 0.528044 \t Best loss: 0.528044 \t Accuracy: 0.806667\n",
      "28 \t Validation loss: 0.527585 \t Best loss: 0.527585 \t Accuracy: 0.8\n",
      "29 \t Validation loss: 0.527233 \t Best loss: 0.527233 \t Accuracy: 0.8\n",
      "30 \t Validation loss: 0.526981 \t Best loss: 0.526981 \t Accuracy: 0.806667\n",
      "31 \t Validation loss: 0.526824 \t Best loss: 0.526824 \t Accuracy: 0.806667\n",
      "32 \t Validation loss: 0.526757 \t Best loss: 0.526757 \t Accuracy: 0.806667\n",
      "33 \t Validation loss: 0.526775 \t Best loss: 0.526757 \t Accuracy: 0.806667\n",
      "34 \t Validation loss: 0.526874 \t Best loss: 0.526757 \t Accuracy: 0.806667\n",
      "35 \t Validation loss: 0.527049 \t Best loss: 0.526757 \t Accuracy: 0.806667\n",
      "36 \t Validation loss: 0.527297 \t Best loss: 0.526757 \t Accuracy: 0.806667\n",
      "37 \t Validation loss: 0.527614 \t Best loss: 0.526757 \t Accuracy: 0.813333\n",
      "38 \t Validation loss: 0.527996 \t Best loss: 0.526757 \t Accuracy: 0.813333\n",
      "39 \t Validation loss: 0.528442 \t Best loss: 0.526757 \t Accuracy: 0.813333\n",
      "40 \t Validation loss: 0.528946 \t Best loss: 0.526757 \t Accuracy: 0.813333\n",
      "41 \t Validation loss: 0.529507 \t Best loss: 0.526757 \t Accuracy: 0.813333\n",
      "42 \t Validation loss: 0.530122 \t Best loss: 0.526757 \t Accuracy: 0.82\n",
      "43 \t Validation loss: 0.530789 \t Best loss: 0.526757 \t Accuracy: 0.82\n",
      "44 \t Validation loss: 0.531504 \t Best loss: 0.526757 \t Accuracy: 0.813333\n",
      "45 \t Validation loss: 0.532266 \t Best loss: 0.526757 \t Accuracy: 0.813333\n",
      "46 \t Validation loss: 0.533072 \t Best loss: 0.526757 \t Accuracy: 0.813333\n",
      "47 \t Validation loss: 0.533921 \t Best loss: 0.526757 \t Accuracy: 0.813333\n",
      "48 \t Validation loss: 0.53481 \t Best loss: 0.526757 \t Accuracy: 0.813333\n",
      "49 \t Validation loss: 0.535738 \t Best loss: 0.526757 \t Accuracy: 0.813333\n",
      "50 \t Validation loss: 0.536703 \t Best loss: 0.526757 \t Accuracy: 0.813333\n",
      "51 \t Validation loss: 0.537703 \t Best loss: 0.526757 \t Accuracy: 0.813333\n",
      "============================================================\n",
      "Test data accurancy 0.822876\n",
      "Time: 3.205981492996216\n",
      "============================================================ \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "t0 = time.time()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "        \n",
    "    # parameters\n",
    "    saturate_count = 0\n",
    "    best_acc = 0.\n",
    "    best_loss = 1000.\n",
    "    best_epoch = -1\n",
    "    iterations = int(X_train2.shape[0] / batch_size)\n",
    "        \n",
    "    # training for number of epochs times\n",
    "    for e in range(1, epochs + 1):\n",
    "        for i in range(iterations):\n",
    "            if(i==0):\n",
    "                batch_x = X_train2[:batch_size]\n",
    "                batch_y = y_train2[:batch_size]\n",
    "            else:\n",
    "                batch_x = X_train2[i * batch_size : (i + 1) * batch_size]\n",
    "                batch_y = y_train2[i * batch_size : (i + 1) * batch_size]\n",
    "                    \n",
    "            sess.run(training_op, feed_dict={X: batch_x, y: batch_y})\n",
    "        \n",
    "        # validate\n",
    "        loss, acc = sess.run([loss_function, accuracy], feed_dict={X: X_valid2, y: y_valid2})\n",
    "        \n",
    "        if best_loss > loss:\n",
    "            best_acc = acc\n",
    "            best_loss = loss\n",
    "            best_epoch = e\n",
    "            saturate_count = 0\n",
    "        else:\n",
    "            saturate_count += 1\n",
    "\n",
    "            if saturate_count >= saturate_limit:  # stop if saturate\n",
    "                t1 = time.time()\n",
    "                break\n",
    "                \n",
    "        print(e,'\\t', 'Validation loss:', loss, '\\t', 'Best loss:', best_loss, '\\t','Accuracy:', acc)\n",
    "    \n",
    "    # print the test data accurancy\n",
    "    print('=' * 60)\n",
    "    print('Test data accurancy', sess.run(accuracy,feed_dict={X: X_test2,\n",
    "                                                              y: y_test2}))\n",
    "    print('Time:', (t1-t0))\n",
    "    print('=' * 60, '\\n')\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HW 3.2 - Caching the 5th layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'dense5/Elu:0' shape=(?, 128) dtype=float32>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrained_weights_path = './pretrained_hw2_weights/Team59_HW2.ckpt.meta'\n",
    "\n",
    "inputs_num = 784\n",
    "outputs_num = 5\n",
    "\n",
    "he_init = tf.contrib.layers.variance_scaling_initializer()\n",
    "\n",
    "tf.reset_default_graph()\n",
    "saver = tf.train.import_meta_graph(pretrained_weights_path)\n",
    "graph = tf.get_default_graph()\n",
    "\n",
    "X = graph.get_tensor_by_name('X:0')\n",
    "y = graph.get_tensor_by_name('y:0')\n",
    "loss_function = graph.get_tensor_by_name('loss:0')\n",
    "Y_prob = graph.get_tensor_by_name('Y_probability:0')\n",
    "logits = Y_prob.op.inputs[0]\n",
    "accuracy = graph.get_tensor_by_name('accuracy:0')\n",
    "\n",
    "output_layer_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope='logits')\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=lr, name='op_HW3-2')\n",
    "training_op = optimizer.minimize(loss_function, var_list=output_layer_vars)\n",
    "\n",
    "# print(tf.get_default_graph().get_operations())\n",
    "\n",
    "# get 5th layer output\n",
    "dense5_output = graph.get_tensor_by_name('logits/MatMul:0')  # logits layer\n",
    "dense5_output.op.inputs[0] # 5th layer output shape(?, 128)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trainging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 \t Validation loss: 1.32267 \t Best loss: 1.32267 \t Accuracy: 0.42\n",
      "2 \t Validation loss: 0.872994 \t Best loss: 0.872994 \t Accuracy: 0.7\n",
      "3 \t Validation loss: 0.733053 \t Best loss: 0.733053 \t Accuracy: 0.766667\n",
      "4 \t Validation loss: 0.673144 \t Best loss: 0.673144 \t Accuracy: 0.78\n",
      "5 \t Validation loss: 0.639253 \t Best loss: 0.639253 \t Accuracy: 0.8\n",
      "6 \t Validation loss: 0.615424 \t Best loss: 0.615424 \t Accuracy: 0.8\n",
      "7 \t Validation loss: 0.598731 \t Best loss: 0.598731 \t Accuracy: 0.793333\n",
      "8 \t Validation loss: 0.58612 \t Best loss: 0.58612 \t Accuracy: 0.8\n",
      "9 \t Validation loss: 0.576396 \t Best loss: 0.576396 \t Accuracy: 0.806667\n",
      "10 \t Validation loss: 0.568662 \t Best loss: 0.568662 \t Accuracy: 0.8\n",
      "11 \t Validation loss: 0.562381 \t Best loss: 0.562381 \t Accuracy: 0.793333\n",
      "12 \t Validation loss: 0.557183 \t Best loss: 0.557183 \t Accuracy: 0.806667\n",
      "13 \t Validation loss: 0.552812 \t Best loss: 0.552812 \t Accuracy: 0.813333\n",
      "14 \t Validation loss: 0.549086 \t Best loss: 0.549086 \t Accuracy: 0.82\n",
      "15 \t Validation loss: 0.545876 \t Best loss: 0.545876 \t Accuracy: 0.82\n",
      "16 \t Validation loss: 0.543085 \t Best loss: 0.543085 \t Accuracy: 0.82\n",
      "17 \t Validation loss: 0.540644 \t Best loss: 0.540644 \t Accuracy: 0.813333\n",
      "18 \t Validation loss: 0.5385 \t Best loss: 0.5385 \t Accuracy: 0.813333\n",
      "19 \t Validation loss: 0.536613 \t Best loss: 0.536613 \t Accuracy: 0.813333\n",
      "20 \t Validation loss: 0.534951 \t Best loss: 0.534951 \t Accuracy: 0.813333\n",
      "21 \t Validation loss: 0.53349 \t Best loss: 0.53349 \t Accuracy: 0.813333\n",
      "22 \t Validation loss: 0.532211 \t Best loss: 0.532211 \t Accuracy: 0.806667\n",
      "23 \t Validation loss: 0.531096 \t Best loss: 0.531096 \t Accuracy: 0.813333\n",
      "24 \t Validation loss: 0.530133 \t Best loss: 0.530133 \t Accuracy: 0.813333\n",
      "25 \t Validation loss: 0.529309 \t Best loss: 0.529309 \t Accuracy: 0.813333\n",
      "26 \t Validation loss: 0.528616 \t Best loss: 0.528616 \t Accuracy: 0.813333\n",
      "27 \t Validation loss: 0.528044 \t Best loss: 0.528044 \t Accuracy: 0.806667\n",
      "28 \t Validation loss: 0.527585 \t Best loss: 0.527585 \t Accuracy: 0.8\n",
      "29 \t Validation loss: 0.527233 \t Best loss: 0.527233 \t Accuracy: 0.8\n",
      "30 \t Validation loss: 0.526981 \t Best loss: 0.526981 \t Accuracy: 0.806667\n",
      "31 \t Validation loss: 0.526824 \t Best loss: 0.526824 \t Accuracy: 0.806667\n",
      "32 \t Validation loss: 0.526757 \t Best loss: 0.526757 \t Accuracy: 0.806667\n",
      "33 \t Validation loss: 0.526775 \t Best loss: 0.526757 \t Accuracy: 0.806667\n",
      "34 \t Validation loss: 0.526874 \t Best loss: 0.526757 \t Accuracy: 0.806667\n",
      "35 \t Validation loss: 0.527049 \t Best loss: 0.526757 \t Accuracy: 0.806667\n",
      "36 \t Validation loss: 0.527297 \t Best loss: 0.526757 \t Accuracy: 0.806667\n",
      "37 \t Validation loss: 0.527614 \t Best loss: 0.526757 \t Accuracy: 0.813333\n",
      "38 \t Validation loss: 0.527997 \t Best loss: 0.526757 \t Accuracy: 0.813333\n",
      "39 \t Validation loss: 0.528442 \t Best loss: 0.526757 \t Accuracy: 0.813333\n",
      "40 \t Validation loss: 0.528946 \t Best loss: 0.526757 \t Accuracy: 0.813333\n",
      "41 \t Validation loss: 0.529507 \t Best loss: 0.526757 \t Accuracy: 0.813333\n",
      "42 \t Validation loss: 0.530122 \t Best loss: 0.526757 \t Accuracy: 0.82\n",
      "43 \t Validation loss: 0.530789 \t Best loss: 0.526757 \t Accuracy: 0.82\n",
      "44 \t Validation loss: 0.531504 \t Best loss: 0.526757 \t Accuracy: 0.813333\n",
      "45 \t Validation loss: 0.532266 \t Best loss: 0.526757 \t Accuracy: 0.813333\n",
      "46 \t Validation loss: 0.533072 \t Best loss: 0.526757 \t Accuracy: 0.813333\n",
      "47 \t Validation loss: 0.533921 \t Best loss: 0.526757 \t Accuracy: 0.813333\n",
      "48 \t Validation loss: 0.53481 \t Best loss: 0.526757 \t Accuracy: 0.813333\n",
      "49 \t Validation loss: 0.535738 \t Best loss: 0.526757 \t Accuracy: 0.813333\n",
      "50 \t Validation loss: 0.536703 \t Best loss: 0.526757 \t Accuracy: 0.813333\n",
      "51 \t Validation loss: 0.537703 \t Best loss: 0.526757 \t Accuracy: 0.813333\n",
      "============================================================\n",
      "Test data accurancy 0.822876\n",
      "Time: 1.4901022911071777\n",
      "============================================================ \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "t0 = time.time()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "        \n",
    "    # parameters\n",
    "    saturate_count = 0\n",
    "    best_acc = 0.\n",
    "    best_loss = 1000.\n",
    "    best_epoch = -1\n",
    "    iterations = int(X_train2.shape[0] / batch_size)\n",
    "    \n",
    "    # feed the X_train2 to get the 5th output\n",
    "    logits_train_input = sess.run(dense5_output.op.inputs[0], feed_dict={X: X_train2})\n",
    "        \n",
    "    # training for number of epochs times\n",
    "    for e in range(1, epochs + 1):\n",
    "        for i in range(iterations):\n",
    "            if(i==0):\n",
    "                batch_x = logits_train_input[:batch_size]\n",
    "                batch_y = y_train2[:batch_size]\n",
    "            else:\n",
    "                batch_x = logits_train_input[i * batch_size : (i + 1) * batch_size]\n",
    "                batch_y = y_train2[i * batch_size : (i + 1) * batch_size]\n",
    "            \n",
    "            sess.run(training_op, feed_dict={dense5_output.op.inputs[0]: batch_x, y: batch_y})\n",
    "        \n",
    "        # validate\n",
    "        logits_valid_input = sess.run(dense5_output.op.inputs[0], feed_dict={X: X_valid2})        \n",
    "        loss, acc = sess.run([loss_function, accuracy], feed_dict={dense5_output.op.inputs[0]: logits_valid_input,\n",
    "                                                                   y: y_valid2})\n",
    "        \n",
    "        if best_loss > loss:\n",
    "            best_acc = acc\n",
    "            best_loss = loss\n",
    "            best_epoch = e\n",
    "            saturate_count = 0\n",
    "        else:\n",
    "            saturate_count += 1\n",
    "\n",
    "            if saturate_count >= saturate_limit:  # stop if saturate\n",
    "                t1 = time.time()\n",
    "                break\n",
    "                \n",
    "        print(e,'\\t', 'Validation loss:', loss, '\\t', 'Best loss:', best_loss, '\\t','Accuracy:', acc)\n",
    "    \n",
    "    # print the test data accurancy\n",
    "    print('=' * 60)\n",
    "    print('Test data accurancy', sess.run(accuracy,feed_dict={X: X_test2,\n",
    "                                                              y: y_test2}))\n",
    "    print('Time:', (t1-t0))\n",
    "    print('=' * 60, '\\n')\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HW 3.3 - 4-layers-only transfer-learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'dense4/Elu:0' shape=(?, 128) dtype=float32>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrained_weights_path = './pretrained_hw2_weights/Team59_HW2.ckpt.meta'\n",
    "\n",
    "inputs_num = 784\n",
    "outputs_num = 5\n",
    "\n",
    "he_init = tf.contrib.layers.variance_scaling_initializer()\n",
    "\n",
    "tf.reset_default_graph()\n",
    "saver = tf.train.import_meta_graph(pretrained_weights_path)\n",
    "graph = tf.get_default_graph()\n",
    "\n",
    "X = graph.get_tensor_by_name('X:0')\n",
    "y = graph.get_tensor_by_name('y:0')\n",
    "loss_function = graph.get_tensor_by_name('loss:0')\n",
    "Y_prob = graph.get_tensor_by_name('Y_probability:0')\n",
    "logits = Y_prob.op.inputs[0]\n",
    "accuracy = graph.get_tensor_by_name('accuracy:0')\n",
    "\n",
    "output_layer_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope='logits')\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=lr, name='op_HW3-3')\n",
    "training_op = optimizer.minimize(loss_function, var_list=output_layer_vars)\n",
    "\n",
    "# print(tf.get_default_graph().get_operations())\n",
    "\n",
    "# get 4th layer output\n",
    "dense4_output = graph.get_tensor_by_name('dense4/Elu:0')  # 4th output\n",
    "dense4_output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 \t Validation loss: 1.32267 \t Best loss: 1.32267 \t Accuracy: 0.42\n",
      "2 \t Validation loss: 0.872994 \t Best loss: 0.872994 \t Accuracy: 0.7\n",
      "3 \t Validation loss: 0.733053 \t Best loss: 0.733053 \t Accuracy: 0.766667\n",
      "4 \t Validation loss: 0.673144 \t Best loss: 0.673144 \t Accuracy: 0.78\n",
      "5 \t Validation loss: 0.639253 \t Best loss: 0.639253 \t Accuracy: 0.8\n",
      "6 \t Validation loss: 0.615424 \t Best loss: 0.615424 \t Accuracy: 0.8\n",
      "7 \t Validation loss: 0.598731 \t Best loss: 0.598731 \t Accuracy: 0.793333\n",
      "8 \t Validation loss: 0.58612 \t Best loss: 0.58612 \t Accuracy: 0.8\n",
      "9 \t Validation loss: 0.576396 \t Best loss: 0.576396 \t Accuracy: 0.806667\n",
      "10 \t Validation loss: 0.568662 \t Best loss: 0.568662 \t Accuracy: 0.8\n",
      "11 \t Validation loss: 0.562381 \t Best loss: 0.562381 \t Accuracy: 0.793333\n",
      "12 \t Validation loss: 0.557183 \t Best loss: 0.557183 \t Accuracy: 0.806667\n",
      "13 \t Validation loss: 0.552812 \t Best loss: 0.552812 \t Accuracy: 0.813333\n",
      "14 \t Validation loss: 0.549086 \t Best loss: 0.549086 \t Accuracy: 0.82\n",
      "15 \t Validation loss: 0.545876 \t Best loss: 0.545876 \t Accuracy: 0.82\n",
      "16 \t Validation loss: 0.543085 \t Best loss: 0.543085 \t Accuracy: 0.82\n",
      "17 \t Validation loss: 0.540644 \t Best loss: 0.540644 \t Accuracy: 0.813333\n",
      "18 \t Validation loss: 0.5385 \t Best loss: 0.5385 \t Accuracy: 0.813333\n",
      "19 \t Validation loss: 0.536613 \t Best loss: 0.536613 \t Accuracy: 0.813333\n",
      "20 \t Validation loss: 0.534951 \t Best loss: 0.534951 \t Accuracy: 0.813333\n",
      "21 \t Validation loss: 0.53349 \t Best loss: 0.53349 \t Accuracy: 0.813333\n",
      "22 \t Validation loss: 0.532211 \t Best loss: 0.532211 \t Accuracy: 0.806667\n",
      "23 \t Validation loss: 0.531096 \t Best loss: 0.531096 \t Accuracy: 0.813333\n",
      "24 \t Validation loss: 0.530133 \t Best loss: 0.530133 \t Accuracy: 0.813333\n",
      "25 \t Validation loss: 0.529309 \t Best loss: 0.529309 \t Accuracy: 0.813333\n",
      "26 \t Validation loss: 0.528616 \t Best loss: 0.528616 \t Accuracy: 0.813333\n",
      "27 \t Validation loss: 0.528044 \t Best loss: 0.528044 \t Accuracy: 0.806667\n",
      "28 \t Validation loss: 0.527585 \t Best loss: 0.527585 \t Accuracy: 0.8\n",
      "29 \t Validation loss: 0.527233 \t Best loss: 0.527233 \t Accuracy: 0.8\n",
      "30 \t Validation loss: 0.526981 \t Best loss: 0.526981 \t Accuracy: 0.806667\n",
      "31 \t Validation loss: 0.526824 \t Best loss: 0.526824 \t Accuracy: 0.806667\n",
      "32 \t Validation loss: 0.526757 \t Best loss: 0.526757 \t Accuracy: 0.806667\n",
      "33 \t Validation loss: 0.526775 \t Best loss: 0.526757 \t Accuracy: 0.806667\n",
      "34 \t Validation loss: 0.526874 \t Best loss: 0.526757 \t Accuracy: 0.806667\n",
      "35 \t Validation loss: 0.527049 \t Best loss: 0.526757 \t Accuracy: 0.806667\n",
      "36 \t Validation loss: 0.527297 \t Best loss: 0.526757 \t Accuracy: 0.806667\n",
      "37 \t Validation loss: 0.527614 \t Best loss: 0.526757 \t Accuracy: 0.813333\n",
      "38 \t Validation loss: 0.527996 \t Best loss: 0.526757 \t Accuracy: 0.813333\n",
      "39 \t Validation loss: 0.528441 \t Best loss: 0.526757 \t Accuracy: 0.813333\n",
      "40 \t Validation loss: 0.528946 \t Best loss: 0.526757 \t Accuracy: 0.813333\n",
      "41 \t Validation loss: 0.529507 \t Best loss: 0.526757 \t Accuracy: 0.813333\n",
      "42 \t Validation loss: 0.530122 \t Best loss: 0.526757 \t Accuracy: 0.82\n",
      "43 \t Validation loss: 0.530789 \t Best loss: 0.526757 \t Accuracy: 0.82\n",
      "44 \t Validation loss: 0.531504 \t Best loss: 0.526757 \t Accuracy: 0.813333\n",
      "45 \t Validation loss: 0.532266 \t Best loss: 0.526757 \t Accuracy: 0.813333\n",
      "46 \t Validation loss: 0.533072 \t Best loss: 0.526757 \t Accuracy: 0.813333\n",
      "47 \t Validation loss: 0.533921 \t Best loss: 0.526757 \t Accuracy: 0.813333\n",
      "48 \t Validation loss: 0.53481 \t Best loss: 0.526757 \t Accuracy: 0.813333\n",
      "49 \t Validation loss: 0.535738 \t Best loss: 0.526757 \t Accuracy: 0.813333\n",
      "50 \t Validation loss: 0.536703 \t Best loss: 0.526757 \t Accuracy: 0.813333\n",
      "51 \t Validation loss: 0.537702 \t Best loss: 0.526757 \t Accuracy: 0.813333\n",
      "============================================================\n",
      "Test data accurancy 0.822876\n",
      "Time: 1.5000979900360107\n",
      "============================================================ \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "t0 = time.time()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "        \n",
    "    # parameters\n",
    "    saturate_count = 0\n",
    "    best_acc = 0.\n",
    "    best_loss = 1000.\n",
    "    best_epoch = -1\n",
    "    iterations = int(X_train2.shape[0] / batch_size)\n",
    "    \n",
    "    # feed the X_train2 to get the 4th output\n",
    "    logits_train_input = sess.run(dense4_output, feed_dict={X: X_train2})\n",
    "        \n",
    "    # training for number of epochs times\n",
    "    for e in range(1, epochs + 1):\n",
    "        for i in range(iterations):\n",
    "            if(i==0):\n",
    "                batch_x = logits_train_input[:batch_size]\n",
    "                batch_y = y_train2[:batch_size]\n",
    "            else:\n",
    "                batch_x = logits_train_input[i * batch_size : (i + 1) * batch_size]\n",
    "                batch_y = y_train2[i * batch_size : (i + 1) * batch_size]\n",
    "            \n",
    "            sess.run(training_op, feed_dict={dense4_output: batch_x, y: batch_y})\n",
    "        \n",
    "        # validate\n",
    "        logits_valid_input = sess.run(dense4_output, feed_dict={X: X_valid2})        \n",
    "        loss, acc = sess.run([loss_function, accuracy], feed_dict={dense4_output: logits_valid_input,\n",
    "                                                                   y: y_valid2})\n",
    "        \n",
    "        if best_loss > loss:\n",
    "            best_acc = acc\n",
    "            best_loss = loss\n",
    "            best_epoch = e\n",
    "            saturate_count = 0\n",
    "        else:\n",
    "            saturate_count += 1\n",
    "\n",
    "            if saturate_count >= saturate_limit:  # stop if saturate\n",
    "                t1 = time.time()\n",
    "                break\n",
    "                \n",
    "        print(e,'\\t', 'Validation loss:', loss, '\\t', 'Best loss:', best_loss, '\\t','Accuracy:', acc)\n",
    "    \n",
    "    # print the test data accurancy\n",
    "    print('=' * 60)\n",
    "    print('Test data accurancy', sess.run(accuracy,feed_dict={X: X_test2,\n",
    "                                                              y: y_test2}))\n",
    "    print('Time:', (t1-t0))\n",
    "    print('=' * 60, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HW 3.4 - Bonus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
